[
  {
    "objectID": "content/01_journal/01_tidyverse.html",
    "href": "content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "The goal of this first challenge is to analyze the sales per state and per year, per state. This page will explain how this analysis was done."
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#header-2",
    "href": "content/01_journal/01_tidyverse.html#header-2",
    "title": "Tidyverse",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/02_data_acquisition.html",
    "href": "content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "The goal of this second challenge is to extract information from the web. This page will explain how this was done.\n\n1 Load libraries\n\n# Load libraries\nlibrary(tidyverse) # Main Package - Loads dplyr, purrr, etc.\nlibrary(gtrendsR)\nlibrary(rvest)     # HTML Hacking & Web Scraping\n\n\n2 Get some data via an API\nFor this exercise, I chose to get the history of Google searches for Eurovision in the last 3 months. I chose to plot the results for some of my favorite entries by defining the “geo” parameter of the gtrends function.\n\nres <- gtrends(c(\"Eurovision Song Contest\"),\n               geo=c(\"DE\", \"FI\", \"NO\", \"SI\", \"HR\"),\n               time = \"today 3-m\")\n\nHere are the correspond ISO codes for the countries that will be plotted: Germany (DE), Finland (FI), Norway (NO), Slovenia (SI), Croatia (HR)\nHere is a plot of the results:\n\nplot(res)\n\n\n\n\n\n\n\n\n3 Scrape data from a competitor website\nRadon bikes was chosen to perform this analysis.\n\n# Define URL\nurl_hardtail <- \"https://www.radon-bikes.de/mountainbike/hardtail/\"\nhtml_hardtail    <- read_html(url_hardtail)\n\nThe SelectorGadget tool was used to get the name of the css nodes for the bike names and bike prices.\n\n# Extract bike info\nbike_names <- list(html_hardtail %>% html_nodes(css = \".a-heading--medium\") %>%  html_text())\nbike_names\n\n#> [[1]]\n#> [1] \"JEALOUS\"    \"JEALOUS AL\" \"CRAGGER\"    \"ZR TEAM\"    \"ZR LADY\"   \n#> [6] \"SLUSH\"\n\nbike_prices <- list(html_hardtail %>% html_nodes(css = \".currentPrice\") %>%  html_text())\nbike_prices\n\n#> [[1]]\n#>  [1] \"2999\" \"\"     \"1199\" \"\"     \"1399\" \"\"     \"749\"  \"\"     \"599\"  \"\"    \n#> [11] \"299\"  \"\"\n\n\nFor some reason, there were some empty xml nodes that were also selected along with the bike prices. This line of code simply eliminates those empty elements.\n\n# Remove empty elements from bike_prices\nbike_prices <- lapply(bike_prices, function(z){ z[!is.na(z) & z != \"\"]})\nbike_prices\n\n#> [[1]]\n#> [1] \"2999\" \"1199\" \"1399\" \"749\"  \"599\"  \"299\"\n\n\nFinally, a table can be created, linking bike names and prices.\n\n# Create table\nbike_infos <- map2_dfr(bike_names, bike_prices, ~ tibble(Name = .x, Price = .y))\nbike_infos"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html",
    "href": "content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "The goal of this third challenge is to examine patent data. This page will explain how this was done."
  },
  {
    "objectID": "content/01_journal/04_data_visualization.html",
    "href": "content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "The goal of this fourth challenge is to analize and visualize COVID-19 data. This page will explain how this was done.\n\n1 Load libraries\n\n# Tidyverse\nlibrary(tidyverse)\n\n\n2 Load data\n\n# Load data\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 311581 Columns: 67\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n3 Challenge 1\nThe goal of this first challenge is to plot the cumulative COVID-19 vases for a few countries.\nFirst you start by wrangling the data:\n\ntotal_cases_over_time <- covid_data_tbl %>%\n  # Select appropriate columns\n  select(iso_code,location, date, total_cases) %>%\n  # Filter based on country\n  filter(location %in% c(\"Germany\", \"United Kingdom\", \"France\", \"Spain\", \"United States\")) %>%\n  # Remove blank values\n  filter(!is.na(total_cases))\n\nThen you plot it:\n\ntotal_cases_over_time %>%\n  # Canvas\n  ggplot(aes(x = date, y = total_cases, color = location)) +\n  # Geometries \n  geom_line(size = 1) +\n  # Formatting\n  expand_limits(y = 0) +\n  scale_x_date(date_breaks = '1 month', date_labels = \"%B-%Y\") + \n  scale_y_continuous(labels=function(x) sprintf(\"%.0fM\", x/1e6)) + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  # Change colour\n  scale_color_brewer(palette = \"Set1\") + \n  # Set legend location\n  theme(legend.position = \"bottom\") +\n  # Labels\n  labs(\n    title = \"COVID-19 confirmed cases worldwide\",\n    subtitle = \"As of 19/04/2022\",\n    x = \"Date\",\n    y = \"Total cases\",\n    color = \"Countries\" # Legend text\n  )\n\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n4 Challenge 2\nThe goal of this challenge is to view the mortality rate of every country due to COVID-19.\nFirst you start by wrangling the data:\n\n# 2.1 Data wrangling ----\n# Example: https://www.datanovia.com/en/blog/how-to-create-a-map-using-ggplot2/\nmortality_tbl <- covid_data_tbl %>%\n  # Keep only CAN and DE + others\n  # filter(location == c(\"Canada\", \"Germany\", \"United Kingdom\", \"United States\", \"Democratic Republic of Congo\")) %>%\n  # Select relevant columns\n  select(location, new_deaths_per_million) %>%\n  # Replace all NAs by zeros\n  replace_na(list(new_deaths_per_million = 0)) %>%\n  # Get sums\n  group_by(location) %>%\n  summarise(total_deaths_per_million = sum(new_deaths_per_million)) %>%\n  # Add death percentage\n  mutate(total_deaths_perc = total_deaths_per_million/1e6) %>%\n  # Change location names to match the world map\n  mutate(location = case_when(\n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location)) %>%\n  distinct()\n\nmortality_tbl\n\n\n\n  \n\n\n\nThe title of the “location” column has to be changed to “region” to match the world map:\n\n# Change location column name to match world map\ncolnames(mortality_tbl)[colnames(mortality_tbl) == \"location\"] = \"region\"\n\nNext, you plot the results:\n\n# Change location column name to match world map\ncolnames(mortality_tbl)[colnames(mortality_tbl) == \"location\"] = \"region\"\n\n# 2.2 Plot ----\n# Get world map\nworld <- map_data(\"world\")\n# Join map and data\ndeaths_map <- left_join(mortality_tbl, world, by=\"region\")\n# Plot results\nggplot(deaths_map, aes(long, lat, group=group)) +\n  geom_polygon(aes(fill = total_deaths_perc), color = \"white\")+\n  # Format legend\n  scale_fill_continuous(name=\"Mortality rate\", labels=scales::percent) +\n  # Labels\n  labs(\n    title = \"Confirmed COVID-19 deaths relative to the size of the population\",\n    subtitle = \"Around 6.2 Million confirmed COVID-19 deaths worldwide\",\n    x = \"\",\n    y = \"\",\n    color = \"Mortality rate\" # Legend text\n  )"
  },
  {
    "objectID": "content/02_notes/05_class_notes.html",
    "href": "content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "content/03_other/06_links.html",
    "href": "content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This website contains the completed challenges for the Business Data Science Basics PBL."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website everytime before you want to upload changes"
  },
  {
    "objectID": "content/01_journal/01_tidyverse_copy.html",
    "href": "content/01_journal/01_tidyverse_copy.html",
    "title": "Tidyverse",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh.\nThis is a .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "content/01_journal/01_tidyverse_copy.html#header-2",
    "href": "content/01_journal/01_tidyverse_copy.html#header-2",
    "title": "Tidyverse",
    "section": "\n2.1 Header 2",
    "text": "2.1 Header 2\nHeader 3\nHeader 4\nHeader 5\nHeader 6"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#manipulate",
    "href": "content/01_journal/01_tidyverse.html#manipulate",
    "title": "Tidyverse",
    "section": "\n5.1 Manipulate",
    "text": "5.1 Manipulate\n\nsales_by_state_tbl <- bike_orderlines_wrangled_tbl %>%\n  # Keep state and total_price columns\n  select(state, total_price) %>%\n  # Group by state (kinda like sort)\n  group_by(state) %>% \n  # Sum sales per state\n  summarize(sales = sum(total_price)) %>%\n  # Convert the column into the currency format\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\nsales_by_state_tbl"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#manipulate-1",
    "href": "content/01_journal/01_tidyverse.html#manipulate-1",
    "title": "Tidyverse",
    "section": "\n6.1 Manipulate",
    "text": "6.1 Manipulate\n\nsales_by_state_year_tbl <- bike_orderlines_wrangled_tbl %>%\n  \n  # Select state, date and total price columns + add a year\n  select(order_date, state, total_price) %>%\n  mutate(year = year(order_date)) %>%\n  \n  # Group by and summarize year and main catgegory\n  group_by(year, state) %>%\n  summarise(sales = sum(total_price)) %>%\n  ungroup() %>%\n  \n  # Format $ Text\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n#> `summarise()` has grouped output by 'year'. You can override using the\n#> `.groups` argument.\n\nsales_by_state_year_tbl"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#visualize",
    "href": "content/01_journal/01_tidyverse.html#visualize",
    "title": "Tidyverse",
    "section": "\n5.2 Visualize",
    "text": "5.2 Visualize\n\nsales_by_state_tbl %>%\n  \n  # Plot with sales(year)\n  ggplot(aes(x = state, y = sales)) +\n  \n  # Geometries\n  geom_col(fill = \"#2DC6D6\") + # Use geom_col for a bar plot\n  geom_label(aes(label = sales_text)) + # Adding labels to the bars\n  \n  # Formatting\n  # Adjust from $ to €\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + \n  labs(\n    title    = \"Revenue by state\",\n    x = \"\", # Override defaults for x and y\n    y = \"Revenue\"\n  )"
  },
  {
    "objectID": "content/01_journal/01_tidyverse.html#visualize-1",
    "href": "content/01_journal/01_tidyverse.html#visualize-1",
    "title": "Tidyverse",
    "section": "\n6.2 Visualize",
    "text": "6.2 Visualize\n\nsales_by_state_year_tbl %>%\n  \n  # Set up x, y, fill\n  ggplot(aes(x = year, y = sales, fill = state)) +\n  \n  # Geometries\n  geom_col() + # Run up to here to get a stacked bar plot\n  \n  # Facet\n  facet_wrap(~ state) +\n  \n  # Formatting\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    title = \"Revenue by year and state\",\n    fill = \"State\" # Changes the legend name\n  )"
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#recent-patent-activity",
    "href": "content/01_journal/03_data_wrangling.html#recent-patent-activity",
    "title": "Data Wrangling",
    "section": "\n3.1 Recent patent activity",
    "text": "3.1 Recent patent activity\nThis task asks to list the top 10 US companies that had the most patents granted in August 2014.\n\n# 2.2 Recent patent activity\n# Merge patent + patent_assignee by patent_id\nmerged_patent_assignee_tbl <- patent_tbl[patent_assignee_tbl, on=c(id = \"patent_id\")]\n\n# Filter to keep only August patents\naugust_patents <- merged_patent_assignee_tbl[format(date, \"%m\") == \"08\"]\n\n# Count nb of patents per company\npatent_nb_august <- august_patents[, .N, by = .(assignee_id)]\ncolnames(patent_nb_august)[colnames(patent_nb_august) == \"N\"] <- \"nb_patents\"\n\n# Merge patent_nb_august + assignee table by assignee_id\nmerged_assignee_august_tbl <- assignee_tbl[patent_nb_august, on=c(id = \"assignee_id\")]\nmerged_assignee_august_tbl <- merged_assignee_august_tbl[!is.na(id)]\nsetorder(merged_assignee_august_tbl, cols=-\"nb_patents\")\n\n# Filter to keep US companies/corporations\ntop_US_august_tbl <- merged_assignee_august_tbl[type==2]\ntop_US_august_tbl\n\n\n\n  \n\n\n\nAs can be seen from the table above, International Business Machines Corporation had the most patents granted in August 2014, with a total of 718."
  },
  {
    "objectID": "content/01_journal/03_data_wrangling.html#innovation-in-tech",
    "href": "content/01_journal/03_data_wrangling.html#innovation-in-tech",
    "title": "Data Wrangling",
    "section": "\n3.2 Innovation in Tech",
    "text": "3.2 Innovation in Tech\nThis task asks to list the top 10 companies (worldwide) with the most patents, along with the top 5 USPTO tech main classes.\nHere are the top 10 companies with the most patents:\n\n# 2.3.1 - Top 10 companies (worldwide) with the most patents\nmerged_assignee_tbl\n\n\n\n  \n\n\n\nHere are the top 5 USPTO main classes:\n\n# 2.3.2 - Top 5 USPTO tech main classes\nnb_mainclass_tbl <- uspc_tbl[, .N, by = .(mainclass_id)]\ncolnames(nb_mainclass_tbl)[colnames(nb_mainclass_tbl) == \"N\"] <- \"nb_patents\"\nsetorder(nb_mainclass_tbl, cols=-\"nb_patents\")\nnb_mainclass_tbl[1:5]\n\n\n\n  \n\n\n\nAs can be seen from the table above, the main class 257 is the most innovative tech sector, with a total of 40 526 patents filed."
  },
  {
    "objectID": "scripts/content/01_journal/01_tidyverse.html",
    "href": "scripts/content/01_journal/01_tidyverse.html",
    "title": "Tidyverse",
    "section": "",
    "text": "The goal of this first challenge is to analyze the sales per state and per year, per state. This page will explain how this analysis was done."
  },
  {
    "objectID": "scripts/content/01_journal/01_tidyverse.html#manipulate",
    "href": "scripts/content/01_journal/01_tidyverse.html#manipulate",
    "title": "Tidyverse",
    "section": "\n5.1 Manipulate",
    "text": "5.1 Manipulate\n\nsales_by_state_tbl <- bike_orderlines_wrangled_tbl %>%\n  # Keep state and total_price columns\n  select(state, total_price) %>%\n  # Group by state (kinda like sort)\n  group_by(state) %>% \n  # Sum sales per state\n  summarize(sales = sum(total_price)) %>%\n  # Convert the column into the currency format\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\nsales_by_state_tbl"
  },
  {
    "objectID": "scripts/content/01_journal/01_tidyverse.html#visualize",
    "href": "scripts/content/01_journal/01_tidyverse.html#visualize",
    "title": "Tidyverse",
    "section": "\n5.2 Visualize",
    "text": "5.2 Visualize\n\nsales_by_state_tbl %>%\n  \n  # Plot with sales(year)\n  ggplot(aes(x = state, y = sales)) +\n  \n  # Geometries\n  geom_col(fill = \"#2DC6D6\") + # Use geom_col for a bar plot\n  geom_label(aes(label = sales_text)) + # Adding labels to the bars\n  \n  # Formatting\n  # Adjust from $ to €\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + \n  labs(\n    title    = \"Revenue by state\",\n    x = \"\", # Override defaults for x and y\n    y = \"Revenue\"\n  )"
  },
  {
    "objectID": "scripts/content/01_journal/01_tidyverse.html#manipulate-1",
    "href": "scripts/content/01_journal/01_tidyverse.html#manipulate-1",
    "title": "Tidyverse",
    "section": "\n6.1 Manipulate",
    "text": "6.1 Manipulate\n\nsales_by_state_year_tbl <- bike_orderlines_wrangled_tbl %>%\n  \n  # Select state, date and total price columns + add a year\n  select(order_date, state, total_price) %>%\n  mutate(year = year(order_date)) %>%\n  \n  # Group by and summarize year and main catgegory\n  group_by(year, state) %>%\n  summarise(sales = sum(total_price)) %>%\n  ungroup() %>%\n  \n  # Format $ Text\n  mutate(sales_text = scales::dollar(sales, big.mark = \".\", \n                                     decimal.mark = \",\", \n                                     prefix = \"\", \n                                     suffix = \" €\"))\n\n#> `summarise()` has grouped output by 'year'. You can override using the\n#> `.groups` argument.\n\nsales_by_state_year_tbl"
  },
  {
    "objectID": "scripts/content/01_journal/01_tidyverse.html#visualize-1",
    "href": "scripts/content/01_journal/01_tidyverse.html#visualize-1",
    "title": "Tidyverse",
    "section": "\n6.2 Visualize",
    "text": "6.2 Visualize\n\nsales_by_state_year_tbl %>%\n  \n  # Set up x, y, fill\n  ggplot(aes(x = year, y = sales, fill = state)) +\n  \n  # Geometries\n  geom_col() + # Run up to here to get a stacked bar plot\n  \n  # Facet\n  facet_wrap(~ state) +\n  \n  # Formatting\n  scale_y_continuous(labels = scales::dollar_format(big.mark = \".\", \n                                                    decimal.mark = \",\", \n                                                    prefix = \"\", \n                                                    suffix = \" €\")) +\n  theme(legend.position = \"bottom\") +\n  labs(\n    title = \"Revenue by year and state\",\n    fill = \"State\" # Changes the legend name\n  )"
  },
  {
    "objectID": "scripts/content/01_journal/01_tidyverse_copy.html",
    "href": "scripts/content/01_journal/01_tidyverse_copy.html",
    "title": "Tidyverse",
    "section": "",
    "text": "Note\n\n\n\nYou can delete everything in here and start fresh.\nThis is a .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "scripts/content/01_journal/01_tidyverse_copy.html#header-2",
    "href": "scripts/content/01_journal/01_tidyverse_copy.html#header-2",
    "title": "Tidyverse",
    "section": "\n2.1 Header 2",
    "text": "2.1 Header 2\nHeader 3\nHeader 4\nHeader 5\nHeader 6"
  },
  {
    "objectID": "scripts/content/01_journal/02_data_acquisition.html",
    "href": "scripts/content/01_journal/02_data_acquisition.html",
    "title": "Data Acquisition",
    "section": "",
    "text": "The goal of this second challenge is to extract information from the web. This page will explain how this was done.\n\n1 Load libraries\n\n# Load libraries\nlibrary(tidyverse) # Main Package - Loads dplyr, purrr, etc.\nlibrary(gtrendsR)\nlibrary(rvest)     # HTML Hacking & Web Scraping\n\n\n2 Get some data via an API\nFor this exercise, I chose to get the history of Google searches for Eurovision in the last 3 months. I chose to plot the results for some of my favorite entries by defining the “geo” parameter of the gtrends function.\n\nres <- gtrends(c(\"Eurovision Song Contest\"),\n               geo=c(\"DE\", \"FI\", \"NO\", \"SI\", \"HR\"),\n               time = \"today 3-m\")\n\nHere are the correspond ISO codes for the countries that will be plotted: Germany (DE), Finland (FI), Norway (NO), Slovenia (SI), Croatia (HR)\nHere is a plot of the results:\n\nplot(res)\n\n\n\n\n\n\n\n\n3 Scrape data from a competitor website\nRadon bikes was chosen to perform this analysis.\n\n# Define URL\nurl_hardtail <- \"https://www.radon-bikes.de/mountainbike/hardtail/\"\nhtml_hardtail    <- read_html(url_hardtail)\n\nThe SelectorGadget tool was used to get the name of the css nodes for the bike names and bike prices.\n\n# Extract bike info\nbike_names <- list(html_hardtail %>% html_nodes(css = \".a-heading--medium\") %>%  html_text())\nbike_names\n\n#> [[1]]\n#> [1] \"JEALOUS\"    \"JEALOUS AL\" \"CRAGGER\"    \"ZR TEAM\"    \"ZR LADY\"   \n#> [6] \"SLUSH\"\n\nbike_prices <- list(html_hardtail %>% html_nodes(css = \".currentPrice\") %>%  html_text())\nbike_prices\n\n#> [[1]]\n#>  [1] \"2999\" \"\"     \"1199\" \"\"     \"1399\" \"\"     \"749\"  \"\"     \"599\"  \"\"    \n#> [11] \"299\"  \"\"\n\n\nFor some reason, there were some empty xml nodes that were also selected along with the bike prices. This line of code simply eliminates those empty elements.\n\n# Remove empty elements from bike_prices\nbike_prices <- lapply(bike_prices, function(z){ z[!is.na(z) & z != \"\"]})\nbike_prices\n\n#> [[1]]\n#> [1] \"2999\" \"1199\" \"1399\" \"749\"  \"599\"  \"299\"\n\n\nFinally, a table can be created, linking bike names and prices.\n\n# Create table\nbike_infos <- map2_dfr(bike_names, bike_prices, ~ tibble(Name = .x, Price = .y))\nbike_infos"
  },
  {
    "objectID": "scripts/content/01_journal/03_data_wrangling.html",
    "href": "scripts/content/01_journal/03_data_wrangling.html",
    "title": "Data Wrangling",
    "section": "",
    "text": "The goal of this third challenge is to examine patent data. This page will explain how this was done."
  },
  {
    "objectID": "scripts/content/01_journal/03_data_wrangling.html#recent-patent-activity",
    "href": "scripts/content/01_journal/03_data_wrangling.html#recent-patent-activity",
    "title": "Data Wrangling",
    "section": "\n3.1 Recent patent activity",
    "text": "3.1 Recent patent activity\nThis task asks to list the top 10 US companies that had the most patents granted in August 2014.\n\n# 2.2 Recent patent activity\n# Merge patent + patent_assignee by patent_id\nmerged_patent_assignee_tbl <- patent_tbl[patent_assignee_tbl, on=c(id = \"patent_id\")]\n\n# Filter to keep only August patents\naugust_patents <- merged_patent_assignee_tbl[format(date, \"%m\") == \"08\"]\n\n# Count nb of patents per company\npatent_nb_august <- august_patents[, .N, by = .(assignee_id)]\ncolnames(patent_nb_august)[colnames(patent_nb_august) == \"N\"] <- \"nb_patents\"\n\n# Merge patent_nb_august + assignee table by assignee_id\nmerged_assignee_august_tbl <- assignee_tbl[patent_nb_august, on=c(id = \"assignee_id\")]\nmerged_assignee_august_tbl <- merged_assignee_august_tbl[!is.na(id)]\nsetorder(merged_assignee_august_tbl, cols=-\"nb_patents\")\n\n# Filter to keep US companies/corporations\ntop_US_august_tbl <- merged_assignee_august_tbl[type==2]\ntop_US_august_tbl\n\n\n\n  \n\n\n\nAs can be seen from the table above, International Business Machines Corporation had the most patents granted in August 2014, with a total of 718."
  },
  {
    "objectID": "scripts/content/01_journal/03_data_wrangling.html#innovation-in-tech",
    "href": "scripts/content/01_journal/03_data_wrangling.html#innovation-in-tech",
    "title": "Data Wrangling",
    "section": "\n3.2 Innovation in Tech",
    "text": "3.2 Innovation in Tech\nThis task asks to list the top 10 companies (worldwide) with the most patents, along with the top 5 USPTO tech main classes.\nHere are the top 10 companies with the most patents:\n\n# 2.3.1 - Top 10 companies (worldwide) with the most patents\nmerged_assignee_tbl\n\n\n\n  \n\n\n\nHere are the top 5 USPTO main classes:\n\n# 2.3.2 - Top 5 USPTO tech main classes\nnb_mainclass_tbl <- uspc_tbl[, .N, by = .(mainclass_id)]\ncolnames(nb_mainclass_tbl)[colnames(nb_mainclass_tbl) == \"N\"] <- \"nb_patents\"\nsetorder(nb_mainclass_tbl, cols=-\"nb_patents\")\nnb_mainclass_tbl[1:5]\n\n\n\n  \n\n\n\nAs can be seen from the table above, the main class 257 is the most innovative tech sector, with a total of 40 526 patents filed."
  },
  {
    "objectID": "scripts/content/01_journal/04_data_visualization.html",
    "href": "scripts/content/01_journal/04_data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "The goal of this fourth challenge is to analize and visualize COVID-19 data. This page will explain how this was done.\n\n1 Load libraries\n\n# Tidyverse\nlibrary(tidyverse)\n\n\n2 Load data\n\n# Load data\ncovid_data_tbl <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\n#> Rows: 311581 Columns: 67\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr   (4): iso_code, continent, location, tests_units\n#> dbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\n#> date  (1): date\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n3 Challenge 1\nThe goal of this first challenge is to plot the cumulative COVID-19 vases for a few countries.\nFirst you start by wrangling the data:\n\ntotal_cases_over_time <- covid_data_tbl %>%\n  # Select appropriate columns\n  select(iso_code,location, date, total_cases) %>%\n  # Filter based on country\n  filter(location %in% c(\"Germany\", \"United Kingdom\", \"France\", \"Spain\", \"United States\")) %>%\n  # Remove blank values\n  filter(!is.na(total_cases))\n\nThen you plot it:\n\ntotal_cases_over_time %>%\n  # Canvas\n  ggplot(aes(x = date, y = total_cases, color = location)) +\n  # Geometries \n  geom_line(size = 1) +\n  # Formatting\n  expand_limits(y = 0) +\n  scale_x_date(date_breaks = '1 month', date_labels = \"%B-%Y\") + \n  scale_y_continuous(labels=function(x) sprintf(\"%.0fM\", x/1e6)) + \n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  # Change colour\n  scale_color_brewer(palette = \"Set1\") + \n  # Set legend location\n  theme(legend.position = \"bottom\") +\n  # Labels\n  labs(\n    title = \"COVID-19 confirmed cases worldwide\",\n    subtitle = \"As of 19/04/2022\",\n    x = \"Date\",\n    y = \"Total cases\",\n    color = \"Countries\" # Legend text\n  )\n\n#> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n#> ℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n4 Challenge 2\nThe goal of this challenge is to view the mortality rate of every country due to COVID-19.\nFirst you start by wrangling the data:\n\n# 2.1 Data wrangling ----\n# Example: https://www.datanovia.com/en/blog/how-to-create-a-map-using-ggplot2/\nmortality_tbl <- covid_data_tbl %>%\n  # Keep only CAN and DE + others\n  # filter(location == c(\"Canada\", \"Germany\", \"United Kingdom\", \"United States\", \"Democratic Republic of Congo\")) %>%\n  # Select relevant columns\n  select(location, new_deaths_per_million) %>%\n  # Replace all NAs by zeros\n  replace_na(list(new_deaths_per_million = 0)) %>%\n  # Get sums\n  group_by(location) %>%\n  summarise(total_deaths_per_million = sum(new_deaths_per_million)) %>%\n  # Add death percentage\n  mutate(total_deaths_perc = total_deaths_per_million/1e6) %>%\n  # Change location names to match the world map\n  mutate(location = case_when(\n    location == \"United Kingdom\" ~ \"UK\",\n    location == \"United States\" ~ \"USA\",\n    location == \"Democratic Republic of Congo\" ~ \"Democratic Republic of the Congo\",\n    TRUE ~ location)) %>%\n  distinct()\n\nmortality_tbl\n\n\n\n  \n\n\n\nThe title of the “location” column has to be changed to “region” to match the world map:\n\n# Change location column name to match world map\ncolnames(mortality_tbl)[colnames(mortality_tbl) == \"location\"] = \"region\"\n\nNext, you plot the results:\n\n# Change location column name to match world map\ncolnames(mortality_tbl)[colnames(mortality_tbl) == \"location\"] = \"region\"\n\n# 2.2 Plot ----\n# Get world map\nworld <- map_data(\"world\")\n# Join map and data\ndeaths_map <- left_join(mortality_tbl, world, by=\"region\")\n# Plot results\nggplot(deaths_map, aes(long, lat, group=group)) +\n  geom_polygon(aes(fill = total_deaths_perc), color = \"white\")+\n  # Format legend\n  scale_fill_continuous(name=\"Mortality rate\", labels=scales::percent) +\n  # Labels\n  labs(\n    title = \"Confirmed COVID-19 deaths relative to the size of the population\",\n    subtitle = \"Around 6.2 Million confirmed COVID-19 deaths worldwide\",\n    x = \"\",\n    y = \"\",\n    color = \"Mortality rate\" # Legend text\n  )"
  },
  {
    "objectID": "scripts/content/02_notes/05_class_notes.html",
    "href": "scripts/content/02_notes/05_class_notes.html",
    "title": "Class Notes",
    "section": "",
    "text": "IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.\nThis is an .qmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a # in front of your text, it will create a top level-header."
  },
  {
    "objectID": "scripts/content/03_other/06_links.html",
    "href": "scripts/content/03_other/06_links.html",
    "title": "Links",
    "section": "",
    "text": "R is a free open-source programming language that can be used for statistical analysis, data-simulation, graphing, and lots of other stuff. Another free program is R-studio, that provides a nice graphic interface for R. Download R first, then download R-studio. Both can run on PCs, Macs or Linux. Students will be learning R in the stats labs using the lab manual .\n\n\n\n\nGoogle is great, Google your problem\nStackoverflow is great, google will often take you there because someone has already asked your question, and someone else has answered, usually many people have answered your question many ways."
  },
  {
    "objectID": "scripts/index.html",
    "href": "scripts/index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This website contains the completed challenges for the Business Data Science Basics (PBL)."
  }
]